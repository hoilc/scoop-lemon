{
    "version": "159",
    "description": "A light weight, transparent proxy server that provides automatic model swapping to llama.cpp's server.",
    "homepage": "https://github.com/mostlygeek/llama-swap",
    "license": "MIT",
    "architecture": {
        "64bit": {
            "url": "https://github.com/mostlygeek/llama-swap/releases/download/v159/llama-swap_159_windows_amd64.zip",
            "hash": "9f4c41be41415b0e895f00d76a02f2c4b914591a634f63970e075d184aa30a9c"
        }
    },
    "bin": "llama-swap.exe",
    "checkver": "github",
    "autoupdate": {
        "architecture": {
            "64bit": {
                "url": "https://github.com/mostlygeek/llama-swap/releases/download/v$version/llama-swap_$version_windows_amd64.zip"
            }
        },
        "hash": {
            "url": "$baseurl/llama-swap_$version_checksums.txt"
        }
    }
}
