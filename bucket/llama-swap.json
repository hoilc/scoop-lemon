{
    "version": "178",
    "description": "A light weight, transparent proxy server that provides automatic model swapping to llama.cpp's server.",
    "homepage": "https://github.com/mostlygeek/llama-swap",
    "license": "MIT",
    "architecture": {
        "64bit": {
            "url": "https://github.com/mostlygeek/llama-swap/releases/download/v178/llama-swap_178_windows_amd64.zip",
            "hash": "1e28288b3e795f398b874199895da8c82563e2fc616ec6c6da71b672e73719c9"
        }
    },
    "bin": "llama-swap.exe",
    "checkver": "github",
    "autoupdate": {
        "architecture": {
            "64bit": {
                "url": "https://github.com/mostlygeek/llama-swap/releases/download/v$version/llama-swap_$version_windows_amd64.zip"
            }
        },
        "hash": {
            "url": "$baseurl/llama-swap_$version_checksums.txt"
        }
    }
}
