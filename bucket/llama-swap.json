{
    "version": "173",
    "description": "A light weight, transparent proxy server that provides automatic model swapping to llama.cpp's server.",
    "homepage": "https://github.com/mostlygeek/llama-swap",
    "license": "MIT",
    "architecture": {
        "64bit": {
            "url": "https://github.com/mostlygeek/llama-swap/releases/download/v173/llama-swap_173_windows_amd64.zip",
            "hash": "fb10d39867a35b9fd9ba0205f929386af403bbea6c5532afc74ba236e6e9a6f3"
        }
    },
    "bin": "llama-swap.exe",
    "checkver": "github",
    "autoupdate": {
        "architecture": {
            "64bit": {
                "url": "https://github.com/mostlygeek/llama-swap/releases/download/v$version/llama-swap_$version_windows_amd64.zip"
            }
        },
        "hash": {
            "url": "$baseurl/llama-swap_$version_checksums.txt"
        }
    }
}
