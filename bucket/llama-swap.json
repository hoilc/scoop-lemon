{
    "version": "174",
    "description": "A light weight, transparent proxy server that provides automatic model swapping to llama.cpp's server.",
    "homepage": "https://github.com/mostlygeek/llama-swap",
    "license": "MIT",
    "architecture": {
        "64bit": {
            "url": "https://github.com/mostlygeek/llama-swap/releases/download/v174/llama-swap_174_windows_amd64.zip",
            "hash": "9768db1fc199da9aa586b6ae1bd64dbad2e5bab9930eedf76950fe5ca76d802a"
        }
    },
    "bin": "llama-swap.exe",
    "checkver": "github",
    "autoupdate": {
        "architecture": {
            "64bit": {
                "url": "https://github.com/mostlygeek/llama-swap/releases/download/v$version/llama-swap_$version_windows_amd64.zip"
            }
        },
        "hash": {
            "url": "$baseurl/llama-swap_$version_checksums.txt"
        }
    }
}
